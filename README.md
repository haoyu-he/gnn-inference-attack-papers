# Privacy for Graph Neural Networks

### 2022

- \[S&P'22\] **LinkTeller: Recovering Private Edges from Graph Neural Networks via Influence Analysis** 
    \[[link](https://github.com/AI-secure/LinkTeller)\]
    - Model inversion - edge
    - Known information: node features
    - Black box
- \[USENIX'22\] **ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models**
    \[[link](https://github.com/liuyugeng/ML-Doctor)\]
    - Membership inference
    - Model inversion
    - Attribute inference
    - Model stealing
    - Task: image
- \[USENIX'22\] **Inference Attacks Against Graph Neural Networks**
    \[[link](https://github.com/Zhangzhk0819/GNN-Embedding-Leaks)\]
    - Property inference attack
    - Subgraph inference attack
    - Graph reconstruction attack
    - Known information: graph embeddings, auxiliary dataset
    - Black box
    - Task: graph embedding

### 2021

- \[IJCAI'21\] **GraphMI: Extracting Private Graph Data from Graph Neural Networks**
    \[[link](https://github.com/zaixizhang/GraphMI)\]
    - Model inversion - edge
    - Known information: node features
    - White box
- \[USENIX'21\] **Stealing Links from Graph Neural Networks**
    \[[link](https://github.com/xinleihe/link_stealing_attack)\]
    - Model inversion - edge
    - 8 attacks: node features/partial graph/shadow dataset are known or not
    - Black box
